# Session 18 - Portfolio Structure & Best Practices

## ğŸ¯ Objectifs de la session
- Structurer un portfolio data science professionnel
- Documenter efficacement vos projets
- PrÃ©senter votre travail sur GitHub
- Se dÃ©marquer auprÃ¨s des recruteurs

---

## ğŸ“ Partie 1 : Structure d'un portfolio data science

### Pourquoi un portfolio ?
- **Prouver vos compÃ©tences** : Montrer, ne pas juste dire
- **Se diffÃ©rencier** : Aller au-delÃ  du CV
- **DÃ©montrer la passion** : Projets personnels montrent l'engagement
- **Raconter une histoire** : Vos projets racontent qui vous Ãªtes

### Qu'inclure dans votre portfolio ?

**2-5 projets de qualitÃ© > 10 projets moyens**

#### Types de projets recommandÃ©s
1. **Projet de bout en bout** - De la collecte Ã  la prÃ©diction
2. **Analyse exploratoire approfondie** - Storytelling avec les donnÃ©es
3. **Projet d'impact** - RÃ©solvant un problÃ¨me rÃ©el
4. **Projet technique** - Montrant vos compÃ©tences avancÃ©es
5. **Contribution open-source** - Collaboration et qualitÃ© du code

#### Structure d'un projet portfolio

```
mon-projet-data/
â”œâ”€â”€ README.md                    # Documentation principale â­
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ .gitignore                   # Fichiers Ã  ignorer
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # DonnÃ©es brutes (si petites)
â”‚   â”œâ”€â”€ processed/               # DonnÃ©es nettoyÃ©es
â”‚   â””â”€â”€ README.md                # Description des donnÃ©es
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_collection.ipynb
â”‚   â”œâ”€â”€ 02_data_cleaning.ipynb
â”‚   â”œâ”€â”€ 03_eda.ipynb
â”‚   â”œâ”€â”€ 04_modeling.ipynb
â”‚   â””â”€â”€ 05_results.ipynb
â”œâ”€â”€ src/                         # Code Python rÃ©utilisable
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ features.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ visualization.py
â”œâ”€â”€ tests/                       # Tests unitaires
â”‚   â”œâ”€â”€ test_data_processing.py
â”‚   â””â”€â”€ test_features.py
â”œâ”€â”€ models/                      # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ model_v1.pkl
â”œâ”€â”€ reports/                     # Rapports et visualisations
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ final_report.pdf
â””â”€â”€ LICENSE                      # Licence du projet
```

---

## ğŸ“ Partie 2 : Ã‰crire un excellent README

### Anatomie d'un README parfait

```markdown
# Titre du Projet

## ğŸ¯ Objectif
Phrase d'accroche dÃ©crivant le problÃ¨me rÃ©solu et l'impact.

## ğŸ“Š Dataset
- **Source** : Lien vers le dataset
- **Taille** : X lignes, Y colonnes
- **Description** : Nature des donnÃ©es

## ğŸ” MÃ©thodologie
1. **Data Collection** : Comment les donnÃ©es ont Ã©tÃ© obtenues
2. **Data Cleaning** : Traitement des valeurs manquantes, outliers
3. **EDA** : Insights clÃ©s dÃ©couverts
4. **Feature Engineering** : Variables crÃ©Ã©es
5. **Modeling** : Algorithmes testÃ©s
6. **Evaluation** : MÃ©triques et rÃ©sultats

## ğŸš€ RÃ©sultats clÃ©s
- **MÃ©trique principale** : 95% accuracy
- **Insight 1** : Description
- **Insight 2** : Description
- **Insight 3** : Description

## ğŸ› ï¸ Technologies utilisÃ©es
- **Python 3.11**
- pandas, numpy, scikit-learn
- matplotlib, seaborn, plotly
- Jupyter Notebook

## ğŸ“ Structure du projet
```
Arborescence avec brÃ¨ve description
```

## ğŸš¦ Installation et utilisation
```bash
# Cloner le repo
git clone https://github.com/username/project.git

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer le notebook
jupyter notebook notebooks/main_analysis.ipynb
```

## ğŸ“ˆ Visualisations
![Viz 1](reports/figures/viz1.png)
*Description de la visualisation*

## ğŸ† Performance du modÃ¨le
| ModÃ¨le | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Logistic Regression | 0.82 | 0.79 | 0.85 | 0.82 |
| Random Forest | **0.87** | 0.84 | 0.89 | 0.86 |
| XGBoost | 0.85 | 0.83 | 0.87 | 0.85 |

## ğŸ”® AmÃ©liorations futures
- [ ] Tester des modÃ¨les deep learning
- [ ] DÃ©ployer en production avec Flask
- [ ] CrÃ©er une API REST

## ğŸ‘¤ Auteur
**Votre Nom**
- LinkedIn : [lien]
- Portfolio : [lien]
- Email : votre@email.com

## ğŸ“„ Licence
MIT License
```

### Conseils pour un README efficace

**âœ… Ã€ faire** :
- Commencer par l'objectif et l'impact
- Utiliser des emojis pour la structure (avec modÃ©ration)
- Inclure des visualisations
- Montrer les rÃ©sultats concrets
- Faciliter la reproductibilitÃ©
- Soigner l'orthographe et la grammaire

**âŒ Ã€ Ã©viter** :
- README trop long (> 2 pages)
- Jargon sans explication
- Pas de contexte sur le projet
- Liens morts
- Code sans documentation

---

## ğŸ¨ Partie 3 : PrÃ©sentation sur GitHub

### Profil GitHub professionnel

#### 1. Photo et bio
```
ğŸ“ Data Scientist | Python | Machine Learning
ğŸ“Š PassionnÃ© par l'analyse de donnÃ©es et la visualisation
ğŸŒ Paris, France
ğŸ“« contact@email.com
```

#### 2. README de profil (optionnel mais recommandÃ©)
CrÃ©er un repo `username/username` avec un README.md :

```markdown
# Salut, je suis [Votre Nom] ğŸ‘‹

## ğŸ”­ Ce sur quoi je travaille
- Analyse prÃ©dictive avec scikit-learn
- Visualisation de donnÃ©es avec Plotly
- Projets de NLP avec transformers

## ğŸŒ± Ce que j'apprends actuellement
- Deep Learning avec PyTorch
- MLOps et dÃ©ploiement de modÃ¨les
- SQL avancÃ© pour Big Data

## ğŸ’¼ Projets rÃ©cents
[![Projet 1](https://github-readme-stats.vercel.app/api/pin/?username=username&repo=projet1)](https://github.com/username/projet1)

## ğŸ“Š Statistiques GitHub
![Stats](https://github-readme-stats.vercel.app/api?username=username&show_icons=true&theme=radical)

## ğŸ› ï¸ CompÃ©tences techniques
![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)
![Pandas](https://img.shields.io/badge/-Pandas-150458?style=flat-square&logo=pandas&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/-Scikit--learn-F7931E?style=flat-square&logo=scikit-learn&logoColor=white)

## ğŸ“« Contact
- LinkedIn : [lien]
- Email : [email]
- Portfolio : [lien]
```

#### 3. Ã‰pingler vos meilleurs projets
- SÃ©lectionnez 6 projets maximum
- Variez les types (ML, EDA, viz, etc.)
- Mettez Ã  jour rÃ©guliÃ¨rement

#### 4. Contributions
- Contribuez Ã  des projets open-source
- RÃ©pondez aux issues
- Participez aux discussions

---

## ğŸ’¡ Partie 4 : Documenter un projet data

### Documentation du code

#### Docstrings Python (Google Style)
```python
def prepare_titanic_data(df, impute_age=True):
    """
    Nettoie et prÃ©pare le dataset Titanic pour la modÃ©lisation.
    
    Args:
        df (pd.DataFrame): Dataset Titanic brut
        impute_age (bool): Si True, impute les Ã¢ges manquants
        
    Returns:
        pd.DataFrame: Dataset nettoyÃ© et avec features engineering
        
    Example:
        >>> df_raw = pd.read_csv('titanic.csv')
        >>> df_clean = prepare_titanic_data(df_raw)
        >>> print(df_clean.shape)
        (891, 15)
        
    Notes:
        - Impute Age avec mÃ©diane par groupe (Pclass, Sex)
        - CrÃ©e FamilySize = SibSp + Parch + 1
        - Encode les variables catÃ©gorielles
    """
    df_clean = df.copy()
    
    if impute_age:
        df_clean['Age'] = df_clean.groupby(['Pclass', 'Sex'])['Age'].transform(
            lambda x: x.fillna(x.median())
        )
    
    df_clean['FamilySize'] = df_clean['SibSp'] + df_clean['Parch'] + 1
    
    return df_clean
```

#### Commentaires dans les notebooks
```python
# =============================================================================
# 1. DATA LOADING AND INITIAL EXPLORATION
# =============================================================================
# Objectif : Charger les donnÃ©es et effectuer une premiÃ¨re exploration

# Charger le dataset
df = pd.read_csv('data/titanic.csv')

# VÃ©rifier la forme et les types
print(f"Dataset : {df.shape[0]} lignes, {df.shape[1]} colonnes")
df.info()

# =============================================================================
# 2. DATA CLEANING
# =============================================================================
# Objectif : Traiter les valeurs manquantes et les outliers

# 2.1. Valeurs manquantes
missing = df.isnull().sum()
print(f"Colonnes avec valeurs manquantes : {missing[missing > 0]}")

# 2.2. Imputation de l'Ã¢ge
# StratÃ©gie : MÃ©diane par groupe (Pclass + Sex)
# Justification : L'Ã¢ge varie selon la classe sociale et le sexe
df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].transform(
    lambda x: x.fillna(x.median())
)
```

### Versioning sÃ©mantique

Pour vos modÃ¨les et pipelines :

```
v1.0.0 â†’ v1.1.0 â†’ v2.0.0
 â”‚  â”‚  â”‚    â”‚  â”‚      â”‚
 â”‚  â”‚  â”‚    â”‚  â”‚      â””â”€ Breaking changes (API modifiÃ©e)
 â”‚  â”‚  â”‚    â”‚  â””â”€ Nouvelles features (rÃ©trocompatible)
 â”‚  â”‚  â”‚    â””â”€ Patch/bugfix
 â”‚  â”‚  â””â”€ Patch
 â”‚  â””â”€ Minor
 â””â”€ Major
```

### Changelog
```markdown
# Changelog

## [1.2.0] - 2024-01-20
### Added
- Ajout de feature engineering : Title extraction
- Nouveau modÃ¨le XGBoost avec hyperparameter tuning

### Changed
- AmÃ©lioration de l'imputation d'Ã¢ge (par groupe)
- Mise Ã  jour de la visualisation des rÃ©sultats

### Fixed
- Correction du bug dans le calcul de FamilySize

## [1.1.0] - 2024-01-15
### Added
- PremiÃ¨re version du pipeline de preprocessing
- ModÃ¨le Random Forest baseline
```

---

## ğŸ¯ Partie 5 : Se dÃ©marquer

### Conseils pour impressionner les recruteurs

#### 1. Montrer le processus, pas juste le rÃ©sultat
- Expliquez vos choix mÃ©thodologiques
- Documentez les Ã©checs et ce que vous avez appris
- Montrez les itÃ©rations et amÃ©liorations

#### 2. QualitÃ© > QuantitÃ©
- 3 projets excellents > 20 projets moyens
- Code propre et documentÃ©
- Notebooks bien structurÃ©s avec storytelling

#### 3. Prouver l'impact mÃ©tier
- Parlez en termes de valeur business
- Quantifiez les rÃ©sultats : "AmÃ©lioration de 15% du chiffre d'affaires"
- Reliez les mÃ©triques techniques aux objectifs mÃ©tier

#### 4. DÃ©montrer l'autonomie
- Projets end-to-end : De l'idÃ©e au dÃ©ploiement
- Collecte de donnÃ©es (web scraping, APIs)
- DÃ©ploiement (Streamlit, Flask, Docker)

#### 5. Collaboration et communication
- README clairs et complets
- Visualisations commentÃ©es
- Contributions open-source
- Articles de blog techniques

### Exemples de projets qui se dÃ©marquent

**ğŸŒŸ Excellent** :
- Titre : "PrÃ©diction du churn clients : RÃ©duction de 25% de l'attrition"
- Dataset personnalisÃ© (web scraping)
- EDA approfondie avec insights mÃ©tier
- Comparaison de 5+ modÃ¨les
- DÃ©ploiement avec API Flask
- Dashboard interactif Plotly
- Tests unitaires et CI/CD
- Documentation complÃ¨te

**â­ Bon** :
- Titre : "Analyse du Titanic : Facteurs de survie"
- Dataset Kaggle
- Data cleaning bien documentÃ©
- Feature engineering crÃ©atif
- Visualisations professionnelles
- ModÃ¨le ML avec tuning
- README dÃ©taillÃ©

**ğŸ“ Basique** :
- Titre : "Titanic"
- Dataset Kaggle
- Notebook unique sans structure
- Code minimal
- Pas de README
- Pas de visualisations

---

## ğŸ› ï¸ Partie 6 : Outils et ressources

### Plateformes pour hÃ©berger votre portfolio

1. **GitHub** (essentiel)
   - Code source
   - Notebooks
   - Documentation

2. **GitHub Pages** (gratuit)
   - Site web statique
   - Portfolio visuel
   - Blog technique

3. **Kaggle** (compÃ©titions et datasets)
   - Kernels publics
   - CompÃ©titions pour se challenger
   - CommunautÃ© active

4. **Medium / Dev.to** (articles)
   - Expliquer vos projets
   - Tutoriels
   - Partager votre expertise

5. **LinkedIn** (rÃ©seau professionnel)
   - Posts sur vos projets
   - Articles longs
   - Networking

### Outils pour amÃ©liorer votre portfolio

**Documentation** :
- MkDocs : Documentation statique
- Sphinx : Documentation Python automatique
- Jupyter Book : Notebooks en livre

**DÃ©ploiement** :
- Streamlit : Apps interactives en Python
- Flask / FastAPI : APIs REST
- Heroku / Railway : HÃ©bergement gratuit

**Visualisation** :
- Plotly : Graphiques interactifs
- Tableau Public : Dashboards
- DataPane : Rapports interactifs

**QualitÃ© du code** :
- Black : Formateur de code
- Pylint / Flake8 : Linters
- pytest : Tests unitaires

---

## ğŸ“Š Partie 7 : Exemples de portfolios inspirants

### Portfolios data science de rÃ©fÃ©rence

1. **Chris Albon** (https://chrisalbon.com)
   - Notes techniques concises
   - Snippets de code rÃ©utilisables
   - Design Ã©purÃ©

2. **Kaggle Grandmasters**
   - Notebooks publics bien documentÃ©s
   - Solutions de compÃ©titions expliquÃ©es
   - Code reproductible

3. **Towards Data Science** (auteurs rÃ©guliers)
   - Articles dÃ©taillÃ©s sur des projets
   - Vulgarisation de concepts complexes
   - Visualisations professionnelles

### Template de portfolio personnel

```
mon-portfolio/
â”œâ”€â”€ index.html              # Page d'accueil
â”œâ”€â”€ projets/
â”‚   â”œâ”€â”€ titanic/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ notebook.html
â”‚   â”‚   â””â”€â”€ images/
â”‚   â”œâ”€â”€ nlp-sentiment/
â”‚   â””â”€â”€ time-series/
â”œâ”€â”€ blog/
â”‚   â”œâ”€â”€ article1.html
â”‚   â””â”€â”€ article2.html
â”œâ”€â”€ about.html              # Ã€ propos
â”œâ”€â”€ contact.html            # Contact
â””â”€â”€ assets/
    â”œâ”€â”€ css/
    â”œâ”€â”€ js/
    â””â”€â”€ images/
```

---

## âœ… Checklist portfolio data science

### Avant de publier un projet

- [ ] README complet et clair
- [ ] Code commentÃ© et structurÃ©
- [ ] Notebooks avec storytelling
- [ ] Visualisations de qualitÃ©
- [ ] requirements.txt Ã  jour
- [ ] .gitignore configurÃ©
- [ ] Licence ajoutÃ©e
- [ ] RÃ©sultats quantifiÃ©s
- [ ] Liens fonctionnels
- [ ] Orthographe vÃ©rifiÃ©e

### Profil GitHub

- [ ] Photo professionnelle
- [ ] Bio descriptive
- [ ] Email de contact
- [ ] LinkedIn liÃ©
- [ ] README de profil
- [ ] 4-6 projets Ã©pinglÃ©s
- [ ] Projets rÃ©cents (< 6 mois)
- [ ] Commits rÃ©guliers

### PrÃ©sence en ligne

- [ ] Portfolio web (optionnel)
- [ ] LinkedIn Ã  jour
- [ ] 1-2 articles techniques (optionnel)
- [ ] Profil Kaggle (pour ML)
- [ ] Stack Overflow (contributions)

---

## ğŸš€ Plan d'action

### Semaine 1-2 : Fondations
1. CrÃ©er/nettoyer votre profil GitHub
2. SÃ©lectionner 2-3 projets existants Ã  amÃ©liorer
3. RÃ©diger un README dÃ©taillÃ© pour chaque projet

### Semaine 3-4 : DÃ©veloppement
1. Structurer correctement vos projets
2. Ajouter de la documentation
3. CrÃ©er des visualisations professionnelles
4. Ajouter des tests et validation

### Semaine 5-6 : PrÃ©sentation
1. CrÃ©er un README de profil GitHub
2. Ã‰pingler vos meilleurs projets
3. RÃ©diger 1 article technique (optionnel)
4. Mettre Ã  jour LinkedIn

### Entretien continu
- Ajouter 1 nouveau projet tous les 2-3 mois
- Mettre Ã  jour les projets existants
- Contribuer Ã  l'open-source
- Partager votre travail (LinkedIn, Twitter)

---

## ğŸ”‘ Points clÃ©s Ã  retenir

1. **QualitÃ© avant quantitÃ©** : 3 excellents projets > 20 moyens
2. **Documentation** : Un projet sans README n'existe pas
3. **Storytelling** : Racontez l'histoire de vos donnÃ©es
4. **Impact mÃ©tier** : Montrez la valeur business
5. **Code propre** : StructurÃ©, commentÃ©, testÃ©
6. **RÃ©gularitÃ©** : Commits frÃ©quents, projets rÃ©cents
7. **Communication** : Expliquez clairement vos choix
8. **AmÃ©lioration continue** : Mettez Ã  jour vos projets

---

## ğŸ“– Ressources complÃ©mentaires

### Guides
- [GitHub README Guide](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes)
- [Data Science Portfolio Guide](https://www.dataquest.io/blog/career-guide-data-science-projects-portfolio/)
- [How to Build a Data Science Portfolio](https://towardsdatascience.com/how-to-build-a-data-science-portfolio-5f566517c79c)

### Inspiration
- [Awesome Data Science](https://github.com/academic/awesome-datascience)
- [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning)
- [Best of ML Python](https://github.com/ml-tooling/best-of-ml-python)

### Outils
- [Shields.io](https://shields.io/) - Badges pour README
- [GitHub Stats](https://github.com/anuraghazra/github-readme-stats) - Statistiques
- [Awesome README](https://github.com/matiassingers/awesome-readme) - Exemples

---

**Bonne chance pour la construction de votre portfolio ! ğŸš€**
