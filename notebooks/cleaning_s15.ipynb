{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 15 - Data Cleaning : Nettoyage du Dataset Titanic\n",
    "\n",
    "## üéØ Objectifs\n",
    "- Diagnostiquer les probl√®mes de qualit√© des donn√©es\n",
    "- Traiter les valeurs manquantes avec diff√©rentes strat√©gies\n",
    "- Cr√©er de nouvelles variables pertinentes (feature engineering)\n",
    "- Exporter un dataset propre et pr√™t pour l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"‚úì Biblioth√®ques import√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Chargement et diagnostic initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es\n",
    "df = pd.read_csv('../data/titanic.csv')\n",
    "\n",
    "print(f\"Dataset charg√© : {df.shape[0]} lignes x {df.shape[1]} colonnes\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations g√©n√©rales\n",
    "print(\"=== INFORMATIONS SUR LE DATASET ===\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "print(\"=== STATISTIQUES DESCRIPTIVES ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 : Analyse des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les valeurs manquantes\n",
    "missing_count = df.isnull().sum()\n",
    "missing_pct = (missing_count / len(df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Nombre': missing_count,\n",
    "    'Pourcentage': missing_pct\n",
    "})\n",
    "\n",
    "print(\"=== VALEURS MANQUANTES ===\")\n",
    "print(missing_df[missing_df['Nombre'] > 0].sort_values('Nombre', ascending=False))\n",
    "\n",
    "# Interpr√©tation\n",
    "print(\"\\nüìä Analyse :\")\n",
    "print(\"- Cabin : 77% manquant ‚Üí colonne peu exploitable\")\n",
    "print(\"- Age : 20% manquant ‚Üí n√©cessite imputation\")\n",
    "print(\"- Embarked : 0.22% manquant ‚Üí facile √† imputer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les patterns de valeurs manquantes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('Patterns de valeurs manquantes (jaune = manquant)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 : D√©tection des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier les doublons complets\n",
    "duplicates = df.duplicated()\n",
    "print(f\"Nombre de doublons complets : {duplicates.sum()}\")\n",
    "\n",
    "# V√©rifier les doublons sur colonnes importantes\n",
    "duplicates_name = df.duplicated(subset=['Name'], keep=False)\n",
    "print(f\"Passagers avec noms identiques : {duplicates_name.sum()}\")\n",
    "\n",
    "if duplicates_name.sum() > 0:\n",
    "    print(\"\\nExemples :\")\n",
    "    print(df[duplicates_name][['Name', 'Age', 'Pclass']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 : D√©tection des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les outliers sur Age et Fare\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Age - Boxplot\n",
    "axes[0, 0].boxplot(df['Age'].dropna())\n",
    "axes[0, 0].set_title('Age - Boxplot')\n",
    "axes[0, 0].set_ylabel('√Çge')\n",
    "\n",
    "# Age - Histogramme\n",
    "axes[0, 1].hist(df['Age'].dropna(), bins=30, edgecolor='black')\n",
    "axes[0, 1].set_title('Age - Distribution')\n",
    "axes[0, 1].set_xlabel('√Çge')\n",
    "axes[0, 1].set_ylabel('Fr√©quence')\n",
    "\n",
    "# Fare - Boxplot\n",
    "axes[1, 0].boxplot(df['Fare'].dropna())\n",
    "axes[1, 0].set_title('Fare - Boxplot')\n",
    "axes[1, 0].set_ylabel('Prix')\n",
    "\n",
    "# Fare - Histogramme\n",
    "axes[1, 1].hist(df['Fare'].dropna(), bins=50, edgecolor='black')\n",
    "axes[1, 1].set_title('Fare - Distribution')\n",
    "axes[1, 1].set_xlabel('Prix')\n",
    "axes[1, 1].set_ylabel('Fr√©quence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©tection des outliers avec m√©thode IQR\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Outliers sur Fare\n",
    "fare_outliers, fare_lower, fare_upper = detect_outliers_iqr(df, 'Fare')\n",
    "print(f\"Outliers sur Fare : {len(fare_outliers)} ({len(fare_outliers)/len(df)*100:.1f}%)\")\n",
    "print(f\"Bornes : [{fare_lower:.2f}, {fare_upper:.2f}]\")\n",
    "print(f\"\\nExemples de prix extr√™mes :\")\n",
    "print(fare_outliers.nlargest(5, 'Fare')[['Name', 'Pclass', 'Fare']])\n",
    "\n",
    "print(\"\\nüí° D√©cision : Garder les outliers de Fare car ils correspondent √† des cabines luxueuses (1√®re classe)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Nettoyage des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une copie pour le nettoyage\n",
    "df_clean = df.copy()\n",
    "print(\"‚úì Copie cr√©√©e pour le nettoyage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 : Traitement de la colonne Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin : 77% manquant ‚Üí cr√©er un indicateur puis supprimer\n",
    "df_clean['HasCabin'] = df_clean['Cabin'].notna().astype(int)\n",
    "\n",
    "print(f\"Passagers avec cabine connue : {df_clean['HasCabin'].sum()} ({df_clean['HasCabin'].mean()*100:.1f}%)\")\n",
    "print(f\"Taux de survie avec cabine : {df_clean[df_clean['HasCabin']==1]['Survived'].mean():.2%}\")\n",
    "print(f\"Taux de survie sans cabine : {df_clean[df_clean['HasCabin']==0]['Survived'].mean():.2%}\")\n",
    "\n",
    "# Supprimer la colonne Cabin\n",
    "df_clean = df_clean.drop('Cabin', axis=1)\n",
    "print(\"\\n‚úì Colonne 'Cabin' supprim√©e, indicateur 'HasCabin' cr√©√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 : Traitement de la colonne Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age : Imputation par m√©diane selon Pclass et Sex\n",
    "print(\"=== IMPUTATION DE L'√ÇGE ===\")\n",
    "print(\"Strat√©gie : M√©diane par groupe (Pclass + Sex)\\n\")\n",
    "\n",
    "# Voir les m√©dianes par groupe\n",
    "age_by_group = df_clean.groupby(['Pclass', 'Sex'])['Age'].median()\n",
    "print(\"√Çges m√©dians par groupe :\")\n",
    "print(age_by_group)\n",
    "\n",
    "# Cr√©er un indicateur de valeur manquante\n",
    "df_clean['Age_was_missing'] = df_clean['Age'].isnull().astype(int)\n",
    "\n",
    "# Imputer\n",
    "df_clean['Age'] = df_clean.groupby(['Pclass', 'Sex'])['Age'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì {df_clean['Age_was_missing'].sum()} valeurs d'√¢ge imput√©es\")\n",
    "print(f\"‚úì Aucune valeur manquante restante : {df_clean['Age'].isnull().sum() == 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 : Traitement de la colonne Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked : 2 valeurs manquantes ‚Üí mode\n",
    "print(\"=== IMPUTATION DU PORT D'EMBARQUEMENT ===\")\n",
    "print(f\"Valeurs manquantes : {df_clean['Embarked'].isnull().sum()}\")\n",
    "\n",
    "# Voir la distribution\n",
    "print(\"\\nDistribution :\")\n",
    "print(df_clean['Embarked'].value_counts())\n",
    "\n",
    "# Imputer avec le mode (valeur la plus fr√©quente)\n",
    "mode_embarked = df_clean['Embarked'].mode()[0]\n",
    "df_clean['Embarked'].fillna(mode_embarked, inplace=True)\n",
    "\n",
    "print(f\"\\n‚úì Valeurs manquantes imput√©es avec '{mode_embarked}' (Southampton)\")\n",
    "print(f\"‚úì Aucune valeur manquante restante : {df_clean['Embarked'].isnull().sum() == 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 : Traitement de la colonne Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare : V√©rifier s'il y a des valeurs manquantes\n",
    "print(f\"Valeurs manquantes dans Fare : {df_clean['Fare'].isnull().sum()}\")\n",
    "\n",
    "if df_clean['Fare'].isnull().sum() > 0:\n",
    "    # Imputer avec la m√©diane de la classe\n",
    "    df_clean['Fare'] = df_clean.groupby('Pclass')['Fare'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    print(\"‚úì Valeurs manquantes imput√©es\")\n",
    "else:\n",
    "    print(\"‚úì Aucune valeur manquante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 : V√©rification finale des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier qu'il n'y a plus de valeurs manquantes (sauf colonnes √† supprimer)\n",
    "print(\"=== V√âRIFICATION FINALE ===\")\n",
    "missing_final = df_clean.isnull().sum()\n",
    "print(missing_final[missing_final > 0])\n",
    "\n",
    "if missing_final.sum() == 0:\n",
    "    print(\"\\n‚úÖ Aucune valeur manquante ! Dataset pr√™t pour le feature engineering.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Il reste des valeurs manquantes √† traiter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 : Taille de la famille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er FamilySize\n",
    "df_clean['FamilySize'] = df_clean['SibSp'] + df_clean['Parch'] + 1\n",
    "\n",
    "print(\"=== FAMILY SIZE ===\")\n",
    "print(f\"Distribution :\")\n",
    "print(df_clean['FamilySize'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nTaille moyenne : {df_clean['FamilySize'].mean():.2f}\")\n",
    "print(f\"Passagers seuls : {(df_clean['FamilySize']==1).sum()} ({(df_clean['FamilySize']==1).mean()*100:.1f}%)\")\n",
    "\n",
    "# Analyser la survie par taille de famille\n",
    "print(\"\\nTaux de survie par taille de famille :\")\n",
    "survival_by_family = df_clean.groupby('FamilySize')['Survived'].mean().sort_values(ascending=False)\n",
    "for size, rate in survival_by_family.items():\n",
    "    print(f\"  Taille {size} : {rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er IsAlone\n",
    "df_clean['IsAlone'] = (df_clean['FamilySize'] == 1).astype(int)\n",
    "\n",
    "print(\"Taux de survie :\")\n",
    "print(f\"  Seuls (IsAlone=1) : {df_clean[df_clean['IsAlone']==1]['Survived'].mean():.2%}\")\n",
    "print(f\"  En famille (IsAlone=0) : {df_clean[df_clean['IsAlone']==0]['Survived'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n‚úì Variables 'FamilySize' et 'IsAlone' cr√©√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 : Cat√©gories de taille de famille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat√©goriser la taille de famille\n",
    "def categorize_family(size):\n",
    "    if size == 1:\n",
    "        return 'Alone'\n",
    "    elif size <= 3:\n",
    "        return 'Small'\n",
    "    elif size <= 5:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Large'\n",
    "\n",
    "df_clean['FamilyCategory'] = df_clean['FamilySize'].apply(categorize_family)\n",
    "\n",
    "print(\"Distribution des cat√©gories :\")\n",
    "print(df_clean['FamilyCategory'].value_counts())\n",
    "\n",
    "print(\"\\nTaux de survie par cat√©gorie :\")\n",
    "print(df_clean.groupby('FamilyCategory')['Survived'].mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 : Extraction du titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le titre du nom\n",
    "df_clean['Title'] = df_clean['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "print(\"=== TITRES EXTRAITS ===\")\n",
    "print(\"Distribution des titres :\")\n",
    "print(df_clean['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplifier les titres rares\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr',\n",
    "    'Miss': 'Miss',\n",
    "    'Mrs': 'Mrs',\n",
    "    'Master': 'Master',\n",
    "    'Dr': 'Rare',\n",
    "    'Rev': 'Rare',\n",
    "    'Col': 'Rare',\n",
    "    'Major': 'Rare',\n",
    "    'Mlle': 'Miss',\n",
    "    'Mme': 'Mrs',\n",
    "    'Ms': 'Miss',\n",
    "    'Lady': 'Rare',\n",
    "    'Countess': 'Rare',\n",
    "    'Capt': 'Rare',\n",
    "    'Jonkheer': 'Rare',\n",
    "    'Don': 'Rare',\n",
    "    'Dona': 'Rare',\n",
    "    'Sir': 'Rare'\n",
    "}\n",
    "\n",
    "df_clean['Title'] = df_clean['Title'].map(title_mapping)\n",
    "df_clean['Title'].fillna('Rare', inplace=True)  # Autres titres ‚Üí Rare\n",
    "\n",
    "print(\"Distribution apr√®s simplification :\")\n",
    "print(df_clean['Title'].value_counts())\n",
    "\n",
    "print(\"\\nTaux de survie par titre :\")\n",
    "print(df_clean.groupby('Title')['Survived'].mean().sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n‚úì Variable 'Title' cr√©√©e et simplifi√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 : Cat√©gories d'√¢ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er des cat√©gories d'√¢ge\n",
    "bins = [0, 12, 18, 35, 60, 100]\n",
    "labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']\n",
    "df_clean['AgeGroup'] = pd.cut(df_clean['Age'], bins=bins, labels=labels)\n",
    "\n",
    "print(\"=== GROUPES D'√ÇGE ===\")\n",
    "print(\"Distribution :\")\n",
    "print(df_clean['AgeGroup'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nTaux de survie par groupe d'√¢ge :\")\n",
    "print(df_clean.groupby('AgeGroup')['Survived'].mean())\n",
    "\n",
    "print(\"\\n‚úì Variable 'AgeGroup' cr√©√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 : Cat√©gories de prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er des cat√©gories de prix (quartiles)\n",
    "df_clean['FareCategory'] = pd.qcut(df_clean['Fare'], q=4, \n",
    "                                     labels=['Low', 'Medium', 'High', 'VeryHigh'])\n",
    "\n",
    "print(\"=== CAT√âGORIES DE PRIX ===\")\n",
    "print(\"Distribution :\")\n",
    "print(df_clean['FareCategory'].value_counts())\n",
    "\n",
    "print(\"\\nTaux de survie par cat√©gorie de prix :\")\n",
    "print(df_clean.groupby('FareCategory')['Survived'].mean())\n",
    "\n",
    "print(\"\\n‚úì Variable 'FareCategory' cr√©√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 : Variables binaires suppl√©mentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Femme ou enfant (priorit√© d'√©vacuation)\n",
    "df_clean['WomanOrChild'] = ((df_clean['Sex'] == 'female') | (df_clean['Age'] < 18)).astype(int)\n",
    "\n",
    "print(\"Taux de survie :\")\n",
    "print(f\"  Femmes/Enfants : {df_clean[df_clean['WomanOrChild']==1]['Survived'].mean():.2%}\")\n",
    "print(f\"  Hommes adultes : {df_clean[df_clean['WomanOrChild']==0]['Survived'].mean():.2%}\")\n",
    "\n",
    "# Classe sup√©rieure (1√®re ou 2√®me)\n",
    "df_clean['UpperClass'] = (df_clean['Pclass'] <= 2).astype(int)\n",
    "\n",
    "print(\"\\nTaux de survie :\")\n",
    "print(f\"  Classes sup. (1&2) : {df_clean[df_clean['UpperClass']==1]['Survived'].mean():.2%}\")\n",
    "print(f\"  3√®me classe : {df_clean[df_clean['UpperClass']==0]['Survived'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n‚úì Variables 'WomanOrChild' et 'UpperClass' cr√©√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 4 : Pr√©paration finale et export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 : Suppression des colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes √† supprimer\n",
    "columns_to_drop = ['PassengerId', 'Name', 'Ticket']\n",
    "\n",
    "print(f\"Colonnes √† supprimer : {columns_to_drop}\")\n",
    "df_clean = df_clean.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"\\n‚úì Colonnes supprim√©es\")\n",
    "print(f\"Dimensions finales : {df_clean.shape[0]} lignes x {df_clean.shape[1]} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 : R√©capitulatif du dataset nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les colonnes finales\n",
    "print(\"=== COLONNES FINALES ===\")\n",
    "for i, col in enumerate(df_clean.columns, 1):\n",
    "    print(f\"{i:2d}. {col:20s} - {df_clean[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques finales\n",
    "print(\"=== STATISTIQUES FINALES ===\")\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu du dataset nettoy√©\n",
    "print(\"=== APER√áU DU DATASET NETTOY√â ===\")\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification finale : aucune valeur manquante\n",
    "print(\"=== V√âRIFICATION FINALE ===\")\n",
    "missing = df_clean.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"‚úÖ Aucune valeur manquante dans le dataset !\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Valeurs manquantes restantes :\")\n",
    "    print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 : Export du dataset nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le dataset nettoy√©\n",
    "output_path = '../data/titanic_clean.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset nettoy√© sauvegard√© : {output_path}\")\n",
    "print(f\"   {df_clean.shape[0]} lignes x {df_clean.shape[1]} colonnes\")\n",
    "print(f\"   Taille du fichier : {pd.read_csv(output_path).memory_usage(deep=True).sum() / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä R√©sum√© du nettoyage\n",
    "\n",
    "### Actions effectu√©es :\n",
    "\n",
    "#### ‚úÖ Traitement des valeurs manquantes\n",
    "- **Cabin** (77% manquant) : Cr√©√© indicateur `HasCabin`, puis supprim√©\n",
    "- **Age** (20% manquant) : Imput√© par m√©diane selon `Pclass` et `Sex`\n",
    "- **Embarked** (2 valeurs) : Imput√© avec le mode (Southampton)\n",
    "\n",
    "#### ‚úÖ Feature Engineering\n",
    "- **FamilySize** : `SibSp + Parch + 1`\n",
    "- **IsAlone** : Indicateur de voyage seul\n",
    "- **FamilyCategory** : Cat√©gories de taille de famille\n",
    "- **Title** : Extraction et simplification des titres\n",
    "- **AgeGroup** : Cat√©gories d'√¢ge\n",
    "- **FareCategory** : Cat√©gories de prix (quartiles)\n",
    "- **WomanOrChild** : Indicateur femme ou enfant\n",
    "- **UpperClass** : Indicateur classe sup√©rieure\n",
    "- **Age_was_missing** : Indicateur d'imputation d'√¢ge\n",
    "\n",
    "#### ‚úÖ Nettoyage\n",
    "- Suppression des colonnes inutiles : `PassengerId`, `Name`, `Ticket`, `Cabin`\n",
    "- Aucune valeur manquante restante\n",
    "- Dataset pr√™t pour l'EDA et la mod√©lisation\n",
    "\n",
    "### Prochaines √©tapes (Session 16) :\n",
    "- Exploration visuelle approfondie (EDA)\n",
    "- Analyse des corr√©lations\n",
    "- R√©ponse √† des questions m√©tier complexes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
