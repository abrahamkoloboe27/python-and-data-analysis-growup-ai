# Session 14 - Introduction √† NumPy & pandas

## üéØ Objectifs de la session
- Ma√Ætriser les bases de NumPy et les arrays multidimensionnels
- Comprendre les structures pandas : Series et DataFrame
- Apprendre l'indexation, le filtrage et les groupements de donn√©es
- Effectuer des calculs et analyses simples sur des datasets r√©els

---

## üìö Partie 1 : NumPy - La base du calcul scientifique

### Pourquoi NumPy ?
NumPy (Numerical Python) est la biblioth√®que fondamentale pour le calcul scientifique en Python :
- **Performance** : 10-100x plus rapide que les listes Python natives
- **Vectorisation** : Op√©rations sur des tableaux entiers sans boucles
- **Base** : Utilis√© par pandas, scikit-learn, TensorFlow, etc.

### Installation et import
```python
# Installation
pip install numpy

# Import conventionnel
import numpy as np
```

### Les Arrays NumPy

#### Cr√©ation d'arrays
```python
# √Ä partir d'une liste
arr = np.array([1, 2, 3, 4, 5])
print(arr)  # [1 2 3 4 5]

# Array 2D (matrice)
matrix = np.array([[1, 2, 3], 
                   [4, 5, 6]])
print(matrix.shape)  # (2, 3) - 2 lignes, 3 colonnes

# Fonctions de cr√©ation utiles
zeros = np.zeros((3, 4))        # Matrice de z√©ros
ones = np.ones((2, 3))          # Matrice de uns
arange = np.arange(0, 10, 2)    # [0, 2, 4, 6, 8]
linspace = np.linspace(0, 1, 5) # 5 valeurs entre 0 et 1
random = np.random.rand(3, 3)   # Valeurs al√©atoires [0, 1)
```

#### Attributs importants
```python
arr = np.array([[1, 2, 3], [4, 5, 6]])

arr.shape      # (2, 3) - dimensions
arr.ndim       # 2 - nombre de dimensions
arr.size       # 6 - nombre total d'√©l√©ments
arr.dtype      # dtype('int64') - type des donn√©es
```

#### Indexation et slicing
```python
arr = np.array([10, 20, 30, 40, 50])

# Indexation simple
arr[0]      # 10
arr[-1]     # 50

# Slicing
arr[1:4]    # [20, 30, 40]
arr[::2]    # [10, 30, 50] - un √©l√©ment sur deux

# Array 2D
matrix = np.array([[1, 2, 3],
                   [4, 5, 6],
                   [7, 8, 9]])

matrix[0, 1]      # 2 - ligne 0, colonne 1
matrix[1, :]      # [4, 5, 6] - toute la ligne 1
matrix[:, 2]      # [3, 6, 9] - toute la colonne 2
matrix[0:2, 1:3]  # [[2, 3], [5, 6]] - sous-matrice
```

#### Op√©rations vectoris√©es
```python
arr = np.array([1, 2, 3, 4, 5])

# Op√©rations arithm√©tiques (√©l√©ment par √©l√©ment)
arr + 10         # [11, 12, 13, 14, 15]
arr * 2          # [2, 4, 6, 8, 10]
arr ** 2         # [1, 4, 9, 16, 25]
np.sqrt(arr)     # [1., 1.41, 1.73, 2., 2.24]

# Op√©rations entre arrays
arr1 = np.array([1, 2, 3])
arr2 = np.array([10, 20, 30])
arr1 + arr2      # [11, 22, 33]
arr1 * arr2      # [10, 40, 90]

# Fonctions d'agr√©gation
arr.sum()        # 15
arr.mean()       # 3.0
arr.std()        # 1.41 (√©cart-type)
arr.min()        # 1
arr.max()        # 5
```

#### Filtrage bool√©en
```python
arr = np.array([10, 25, 30, 15, 40])

# Condition bool√©enne
mask = arr > 20
print(mask)          # [False, True, True, False, True]

# Filtrage
arr[arr > 20]        # [25, 30, 40]
arr[(arr > 15) & (arr < 35)]  # [25, 30]
```

---

## üìä Partie 2 : pandas - L'analyse de donn√©es

### Pourquoi pandas ?
pandas est LA biblioth√®que pour l'analyse de donn√©es en Python :
- **DataFrames** : Tables de donn√©es comme Excel/SQL
- **Manipulation facile** : Filtrage, groupement, jointures
- **Gestion des donn√©es manquantes**
- **Import/Export** : CSV, Excel, SQL, JSON, etc.

### Installation et import
```python
# Installation
pip install pandas

# Import conventionnel
import pandas as pd
```

### Series - Vecteur de donn√©es 1D

Une Series est un array 1D avec un index :

```python
# Cr√©ation d'une Series
s = pd.Series([10, 20, 30, 40, 50])
print(s)
# 0    10
# 1    20
# 2    30
# 3    40
# 4    50
# dtype: int64

# Series avec index personnalis√©
s = pd.Series([10, 20, 30], index=['a', 'b', 'c'])
print(s['b'])  # 20

# √Ä partir d'un dictionnaire
data = {'Paris': 2165000, 'Lyon': 513000, 'Marseille': 869000}
population = pd.Series(data)
print(population['Lyon'])  # 513000

# Op√©rations sur Series
population * 2               # Double chaque valeur
population[population > 600000]  # Filtrage
population.mean()            # Moyenne
population.sort_values()     # Tri par valeurs
```

### DataFrame - Table de donn√©es 2D

Un DataFrame est une table avec lignes et colonnes :

```python
# Cr√©ation √† partir d'un dictionnaire
data = {
    'nom': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'age': [25, 30, 35, 28],
    'ville': ['Paris', 'Lyon', 'Paris', 'Marseille'],
    'salaire': [35000, 42000, 48000, 40000]
}
df = pd.DataFrame(data)
print(df)
#       nom  age      ville  salaire
# 0   Alice   25      Paris    35000
# 1     Bob   30       Lyon    42000
# 2 Charlie   35      Paris    48000
# 3   Diana   28  Marseille    40000
```

#### Exploration basique
```python
# Informations g√©n√©rales
df.shape            # (4, 4) - 4 lignes, 4 colonnes
df.columns          # ['nom', 'age', 'ville', 'salaire']
df.index            # RangeIndex(start=0, stop=4, step=1)
df.dtypes           # Types de chaque colonne
df.info()           # R√©sum√© complet

# Aper√ßu des donn√©es
df.head()           # 5 premi√®res lignes
df.head(2)          # 2 premi√®res lignes
df.tail()           # 5 derni√®res lignes
df.sample(2)        # 2 lignes al√©atoires

# Statistiques descriptives
df.describe()       # Stats sur colonnes num√©riques
df['age'].mean()    # √Çge moyen
df['salaire'].median()  # Salaire m√©dian
```

#### S√©lection de colonnes
```python
# Une colonne (retourne une Series)
df['nom']
df.nom              # Notation avec point (si pas d'espace)

# Plusieurs colonnes (retourne un DataFrame)
df[['nom', 'age']]

# Cr√©er une nouvelle colonne
df['salaire_mensuel'] = df['salaire'] / 12
df['senior'] = df['age'] >= 30  # Colonne bool√©enne
```

#### Indexation : loc et iloc

**iloc** : Indexation par **position** (entiers)
```python
# Une cellule
df.iloc[0, 1]           # Ligne 0, colonne 1 ‚Üí 25

# Lignes
df.iloc[0]              # Premi√®re ligne
df.iloc[1:3]            # Lignes 1 et 2

# Sous-ensemble
df.iloc[0:2, 0:2]       # 2 premi√®res lignes, 2 premi√®res colonnes
df.iloc[:, [0, 2]]      # Toutes lignes, colonnes 0 et 2
```

**loc** : Indexation par **labels** (noms)
```python
# Par nom de colonne
df.loc[0, 'nom']        # 'Alice'

# Lignes et colonnes
df.loc[0:2, 'nom':'ville']  # Lignes 0-2, colonnes nom √† ville
df.loc[:, ['nom', 'salaire']]  # Toutes lignes, colonnes sp√©cifiques
```

#### Filtrage (Boolean Indexing)
```python
# Condition simple
df[df['age'] > 28]                  # Personnes de plus de 28 ans

# Conditions multiples (& pour ET, | pour OU)
df[(df['age'] > 25) & (df['ville'] == 'Paris')]
df[(df['age'] < 30) | (df['salaire'] > 45000)]

# M√©thode isin()
df[df['ville'].isin(['Paris', 'Lyon'])]

# Filtrage sur cha√Ænes
df[df['nom'].str.startswith('A')]   # Noms commen√ßant par A
df[df['nom'].str.contains('a')]     # Noms contenant 'a'
```

#### Tri
```python
# Tri par une colonne
df.sort_values('age')                      # Ordre croissant
df.sort_values('salaire', ascending=False) # Ordre d√©croissant

# Tri par plusieurs colonnes
df.sort_values(['ville', 'age'])

# Tri par index
df.sort_index()
```

### Groupement et agr√©gation

Le **groupby** est essentiel pour les analyses :

```python
# Grouper par une colonne et calculer des statistiques
df.groupby('ville')['salaire'].mean()
# ville
# Lyon         42000.0
# Marseille    40000.0
# Paris        41500.0

# Plusieurs agr√©gations
df.groupby('ville')['salaire'].agg(['mean', 'min', 'max', 'count'])

# Grouper par plusieurs colonnes
df.groupby(['ville', 'senior'])['salaire'].mean()

# Compter les occurrences
df['ville'].value_counts()
# Paris        2
# Lyon         1
# Marseille    1
```

---

## üöÄ Partie 3 : Charger et analyser des donn√©es r√©elles

### Lecture de fichiers CSV
```python
import pandas as pd

# Lire un CSV
df = pd.read_csv('data/titanic.csv')

# Options utiles
df = pd.read_csv('data/titanic.csv',
                 sep=',',           # S√©parateur
                 encoding='utf-8',  # Encodage
                 na_values=['?', 'N/A'])  # Valeurs manquantes

# Autres formats
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')
df = pd.read_json('data.json')
df = pd.read_sql_query('SELECT * FROM table', connection)
```

### Export de donn√©es
```python
# Sauvegarder en CSV
df.to_csv('output.csv', index=False)  # index=False pour ne pas sauver l'index

# Autres formats
df.to_excel('output.xlsx', sheet_name='Data', index=False)
df.to_json('output.json', orient='records')
df.to_html('output.html')
```

---

## üí° Analyse du dataset Titanic

Le dataset Titanic contient des informations sur les passagers :

### Colonnes principales
- **PassengerId** : ID unique du passager
- **Survived** : Survie (0 = Non, 1 = Oui)
- **Pclass** : Classe du billet (1, 2, 3)
- **Name** : Nom du passager
- **Sex** : Sexe (male/female)
- **Age** : √Çge en ann√©es
- **SibSp** : Nombre de fr√®res/s≈ìurs/conjoints √† bord
- **Parch** : Nombre de parents/enfants √† bord
- **Ticket** : Num√©ro de billet
- **Fare** : Prix du billet
- **Cabin** : Num√©ro de cabine
- **Embarked** : Port d'embarquement (C = Cherbourg, Q = Queenstown, S = Southampton)

### Questions d'analyse typiques
1. Quel est le taux de survie global ?
2. Quel est le taux de survie par classe ?
3. Les femmes ont-elles mieux surv√©cu que les hommes ?
4. Quel est l'√¢ge moyen des passagers ?
5. Y a-t-il une corr√©lation entre le prix du billet et la survie ?

### Exemple d'analyse rapide
```python
import pandas as pd

# Charger les donn√©es
df = pd.read_csv('data/titanic.csv')

# Exploration rapide
print(df.shape)          # Nombre de lignes et colonnes
print(df.head())         # Premi√®res lignes
print(df.info())         # Types et valeurs manquantes
print(df.describe())     # Statistiques descriptives

# Analyses simples
survival_rate = df['Survived'].mean()
print(f"Taux de survie global : {survival_rate:.2%}")

# Survie par classe
survival_by_class = df.groupby('Pclass')['Survived'].mean()
print("\nTaux de survie par classe :")
print(survival_by_class)

# Survie par sexe
survival_by_sex = df.groupby('Sex')['Survived'].mean()
print("\nTaux de survie par sexe :")
print(survival_by_sex)

# √Çge moyen
avg_age = df['Age'].mean()
print(f"\n√Çge moyen : {avg_age:.1f} ans")
```

---

## üéì Exercices pratiques

### Exercice 1 : NumPy basics
```python
# Cr√©er un array avec les nombres de 0 √† 99
# Reshape en matrice 10x10
# Calculer la somme de chaque ligne
# Trouver le maximum de chaque colonne
```

### Exercice 2 : pandas Series
```python
# Cr√©er une Series avec les populations de 5 villes fran√ßaises
# Trier par ordre d√©croissant
# Afficher les villes avec plus de 500 000 habitants
# Calculer la population totale
```

### Exercice 3 : DataFrame manipulation
```python
# Charger le dataset Titanic
# Afficher les 10 premi√®res lignes
# Compter le nombre de valeurs manquantes par colonne
# Filtrer les passagers de premi√®re classe
# Calculer l'√¢ge moyen par sexe
```

### Exercice 4 : Groupby
```python
# Grouper par classe et calculer le prix moyen du billet
# Grouper par port d'embarquement et compter les passagers
# Calculer le taux de survie par classe et par sexe
```

---

## üìñ Ressources compl√©mentaires

### Documentation officielle
- [NumPy User Guide](https://numpy.org/doc/stable/user/)
- [pandas User Guide](https://pandas.pydata.org/docs/user_guide/)
- [pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)

### Tutoriels recommand√©s
- [NumPy Quickstart](https://numpy.org/doc/stable/user/quickstart.html)
- [10 minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)

### Datasets pour pratiquer
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/)
- [Data.gouv.fr](https://www.data.gouv.fr/)

---

## üîë Points cl√©s √† retenir

1. **NumPy** : Arrays rapides, op√©rations vectoris√©es, base du calcul scientifique
2. **Series** : Vecteur 1D avec index, similaire √† une colonne
3. **DataFrame** : Table 2D avec lignes et colonnes, c≈ìur de pandas
4. **Indexation** : `iloc` (position) vs `loc` (labels)
5. **Filtrage** : Conditions bool√©ennes avec `&` et `|`
6. **Groupby** : Grouper et agr√©ger pour r√©sumer les donn√©es
7. **M√©thodes essentielles** : `head()`, `info()`, `describe()`, `value_counts()`

---

## üìù Pr√©paration pour la prochaine session

Dans la **Session 15**, nous verrons :
- Le nettoyage de donn√©es (valeurs manquantes, outliers)
- Les transformations de types
- La cr√©ation de nouvelles variables (feature engineering)
- L'export de donn√©es propres

**Pr√©paration** :
- Assurez-vous que pandas et NumPy sont install√©s
- Explorez le dataset Titanic avec les commandes de base
- Identifiez les colonnes avec des valeurs manquantes
